{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Predição de Sucesso de Startups\n",
    "\n",
    "## 1. Introdução\n",
    "\n",
    "Este notebook documenta o processo de desenvolvimento de um modelo preditivo para identificar o sucesso ou insucesso de startups, com base em um conjunto de dados fornecido. O objetivo é seguir as etapas de um projeto de Machine Learning, desde a exploração dos dados até a avaliação e otimização do modelo, atendendo aos critérios de avaliação estabelecidos.\n",
    "\n",
    "## 2. Carregamento e Exploração Inicial dos Dados\n",
    "\n",
    "Primeira etapa: carregar os dados de treino e teste para compreender sua estrutura e características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Carregar os dados\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print('Dados de Treino:')\n",
    "print(train.head())\n",
    "print('\\nInformações do Treino:')\n",
    "print(train.info())\n",
    "print('\\nDados de Teste:')\n",
    "print(test.head())\n",
    "print('\\nInformações do Teste:')\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Limpeza e Tratamento de Valores Nulos\n",
    "\n",
    "A limpeza e o tratamento de valores nulos e *outliers* são etapas cruciais para garantir a qualidade dos dados e a robustez do modelo. O código base (`05.py` corrigido) implementa uma estratégia avançada para lidar com esses aspectos.\n",
    "\n",
    "### 3.1. Tratamento de Valores Ausentes (NaN)\n",
    "\n",
    "A função `advanced_preprocessing_pipeline` trata os valores ausentes de forma inteligente:\n",
    "\n",
    "* **Features de Localização e Indústria**: Para features categóricas como `state_code`, `city`, `industry`, etc., os valores ausentes são preenchidos com a **moda** (valor mais frequente) da coluna.\n",
    "\n",
    "* **Features Financeiras**: Para `founded_year`, `total_funding_usd`, `employee_count`, e outras features financeiras críticas, é utilizada a **mediana** para imputação, que é mais robusta contra *outliers*.\n",
    "\n",
    "* **Outras Features Numéricas**: Para as demais features numéricas, a imputação é feita utilizando a **mediana** (`SimpleImputer(strategy='median')`). A mediana é preferível à média em distribuições assimétricas, comuns em dados de startups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores ausentes\n",
    "print('Valores ausentes no conjunto de treino:')\n",
    "missing_train = train.isnull().sum()\n",
    "print(missing_train[missing_train > 0].sort_values(ascending=False))\n",
    "\n",
    "print('\\nValores ausentes no conjunto de teste:')\n",
    "missing_test = test.isnull().sum()\n",
    "print(missing_test[missing_test > 0].sort_values(ascending=False))\n",
    "\n",
    "# Análise básica da variável target\n",
    "print('\\nDistribuição da variável target:')\n",
    "print(train['labels'].value_counts())\n",
    "print('\\nProporção:')\n",
    "print(train['labels'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análise Exploratória e Visualizações\n",
    "\n",
    "Análise das principais características dos dados para entender melhor os padrões que podem indicar o sucesso de startups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar o estilo dos gráficos\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Análise da distribuição da variável target\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Distribuição da variável target\n",
    "train['labels'].value_counts().plot(kind='bar', ax=axes[0,0])\n",
    "axes[0,0].set_title('Distribuição da Variável Target')\n",
    "axes[0,0].set_xlabel('Labels (0=Insucesso, 1=Sucesso)')\n",
    "\n",
    "# Distribuição por indústria\n",
    "if 'industry' in train.columns:\n",
    "    top_industries = train['industry'].value_counts().head(10)\n",
    "    top_industries.plot(kind='barh', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Top 10 Indústrias')\n",
    "\n",
    "# Distribuição por estado\n",
    "if 'state_code' in train.columns:\n",
    "    top_states = train['state_code'].value_counts().head(10)\n",
    "    top_states.plot(kind='bar', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Top 10 Estados')\n",
    "\n",
    "# Distribuição de funding\n",
    "if 'total_funding_usd' in train.columns:\n",
    "    train['total_funding_usd'].hist(bins=50, ax=axes[1,1], alpha=0.7)\n",
    "    axes[1,1].set_title('Distribuição do Funding Total (USD)')\n",
    "    axes[1,1].set_xlabel('Total Funding USD')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pré-processamento e Preparação dos Dados\n",
    "\n",
    "Implementação do pipeline de pré-processamento baseado no código `05.py` otimizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de pré-processamento baseada no 05.py\n",
    "def preprocess_data(train_df, test_df):\n",
    "    # Fazer cópias para não modificar os originais\n",
    "    train_proc = train_df.copy()\n",
    "    test_proc = test_df.copy()\n",
    "    \n",
    "    # Separar features e target\n",
    "    if 'labels' in train_proc.columns:\n",
    "        y = train_proc['labels']\n",
    "        train_proc = train_proc.drop(['labels'], axis=1)\n",
    "    \n",
    "    # Remover colunas de ID se existirem\n",
    "    id_cols = ['id', 'Unnamed: 0']\n",
    "    for col in id_cols:\n",
    "        if col in train_proc.columns:\n",
    "            train_proc = train_proc.drop(col, axis=1)\n",
    "        if col in test_proc.columns:\n",
    "            test_proc = test_proc.drop(col, axis=1)\n",
    "    \n",
    "    # Identificar colunas categóricas e numéricas\n",
    "    categorical_cols = train_proc.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = train_proc.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    # Tratar valores ausentes\n",
    "    # Para colunas categóricas: preencher com moda\n",
    "    for col in categorical_cols:\n",
    "        mode_val = train_proc[col].mode()[0] if len(train_proc[col].mode()) > 0 else 'Unknown'\n",
    "        train_proc[col].fillna(mode_val, inplace=True)\n",
    "        test_proc[col].fillna(mode_val, inplace=True)\n",
    "    \n",
    "    # Para colunas numéricas: preencher com mediana\n",
    "    for col in numerical_cols:\n",
    "        median_val = train_proc[col].median()\n",
    "        train_proc[col].fillna(median_val, inplace=True)\n",
    "        test_proc[col].fillna(median_val, inplace=True)\n",
    "    \n",
    "    # Encoding de variáveis categóricas\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        # Fit no conjunto combinado para garantir consistência\n",
    "        combined_values = pd.concat([train_proc[col], test_proc[col]]).unique()\n",
    "        le.fit(combined_values)\n",
    "        \n",
    "        train_proc[col] = le.transform(train_proc[col])\n",
    "        test_proc[col] = le.transform(test_proc[col])\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    return train_proc, test_proc, y, label_encoders\n",
    "\n",
    "# Aplicar pré-processamento\n",
    "X_train_proc, X_test_proc, y_train, encoders = preprocess_data(train, test)\n",
    "\n",
    "print(f'Shape do treino processado: {X_train_proc.shape}')\n",
    "print(f'Shape do teste processado: {X_test_proc.shape}')\n",
    "print(f'Colunas após processamento: {len(X_train_proc.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Treinamento e Avaliação do Modelo\n",
    "\n",
    "Implementação do modelo ensemble baseado no código otimizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados de treino para validação\n",
    "X_train, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train_proc, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test_proc)\n",
    "\n",
    "# Criar modelo ensemble\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=10, \n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    class_weight='balanced', \n",
    "    random_state=42, \n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "svm_model = SVC(\n",
    "    class_weight='balanced', \n",
    "    probability=True, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ensemble com voting\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('lr', lr_model),\n",
    "        ('svm', svm_model)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "print('Treinando modelo ensemble...')\n",
    "ensemble.fit(X_train_scaled, y_train_split)\n",
    "\n",
    "# Avaliar no conjunto de validação\n",
    "val_predictions = ensemble.predict(X_val_scaled)\n",
    "val_probabilities = ensemble.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "# Métricas de avaliação\n",
    "print('\\nResultados na Validação:')\n",
    "print(classification_report(y_val, val_predictions))\n",
    "print(f'\\nROC AUC Score: {roc_auc_score(y_val, val_probabilities):.4f}')\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_val, val_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusão - Validação')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Valor Predito')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Predições Finais e Submissão\n",
    "\n",
    "Geração das predições finais para o conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo final com todos os dados de treino\n",
    "print('Treinando modelo final com todos os dados...')\n",
    "final_scaler = StandardScaler()\n",
    "X_train_final = final_scaler.fit_transform(X_train_proc)\n",
    "X_test_final = final_scaler.transform(X_test_proc)\n",
    "\n",
    "# Treinar modelo final\n",
    "final_ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42)),\n",
    "        ('lr', LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)),\n",
    "        ('svm', SVC(class_weight='balanced', probability=True, random_state=42))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "final_ensemble.fit(X_train_final, y_train)\n",
    "\n",
    "# Fazer predições finais\n",
    "final_predictions = final_ensemble.predict(X_test_final)\n",
    "final_probabilities = final_ensemble.predict_proba(X_test_final)[:, 1]\n",
    "\n",
    "# Criar arquivo de submissão\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'labels': final_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Arquivo de submissão gerado: submission.csv')\n",
    "\n",
    "# Mostrar estatísticas da predição\n",
    "print(f'\\nDistribuição das predições:')\n",
    "print(submission['labels'].value_counts())\n",
    "print(f'\\nProporção de sucessos preditos: {submission[\"labels\"].mean():.3f}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}